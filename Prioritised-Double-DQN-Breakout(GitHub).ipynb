{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prioritised Double Deep Q-Learning for Atari Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Many imports\n",
    "import retro\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "import cv2\n",
    "import itertools\n",
    "from retro.examples.discretizer import Discretizer\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter \n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env_Wrap:\n",
    "    def __init__(self, state_len, num_frame_skip):\n",
    "        #Initiate Environment Wrapper\n",
    "        self.env = retro.RetroEnv(game='Breakout-Atari2600')\n",
    "        \n",
    "        # Define action space in terms of valid combinations of button presses\n",
    "        combos = [['BUTTON'],['LEFT'],['RIGHT'],[]]\n",
    "        self.action_space_size = len(combos)\n",
    "        self.env = Discretizer(self.env, combos=combos)\n",
    "        \n",
    "        #Number of frames to skip\n",
    "        self.num_frame_skip = num_frame_skip \n",
    "        self.num_frame_skip_1 = num_frame_skip - 3\n",
    "        \n",
    "        #Number of frames in each state\n",
    "        self.state_len = state_len\n",
    "        \n",
    "        _ = self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        #Frame buffer\n",
    "        self.frame_buffer = np.zeros((80,80,2))\n",
    "        \n",
    "        #Hold the previous 4 states\n",
    "        self.state_queue = Queue(maxsize = self.state_len)\n",
    "        #Fill state queue with empty states\n",
    "        for i in range(self.state_len):\n",
    "            self.state_queue.put(np.zeros((80,80)))\n",
    "        \n",
    "        self.env.reset()\n",
    "        #Take NOOP action \n",
    "        for _ in range(15):\n",
    "            state,_,_,_ = self.step(3)\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        next_step, reward, terminal, info = self.frame_skip(action)\n",
    "        _ = self.state_queue.get()\n",
    "        self.state_queue.put(next_step)\n",
    "        state = np.stack(list(self.state_queue.queue)).astype(np.uint8)\n",
    "        \n",
    "        return state, reward, terminal, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "    \n",
    "    def frame_skip(self, action):\n",
    "        \n",
    "        total_reward = 0.0\n",
    "        for skip in range(self.num_frame_skip):\n",
    "        \n",
    "            if skip > self.num_frame_skip_1:\n",
    "                obs, rew, done, info = self.env.step(action)\n",
    "                self.frame_buffer[:,:,skip-(self.num_frame_skip-2)] = self.grayscale_downsample_crop(obs)\n",
    "            \n",
    "            else:\n",
    "                obs, rew, done, info = self.env.step(action)\n",
    "                \n",
    "            total_reward += rew\n",
    "        \n",
    "        max_pool = np.maximum(self.frame_buffer[:,:,0],self.frame_buffer[:,:,1])\n",
    "        \n",
    "        return max_pool, total_reward, done, info\n",
    "    \n",
    "    def grayscale_downsample_crop(self, frame):\n",
    "        #Frames are coverted to gray scale, downsampled by 50% and cropped to 80x80 \n",
    "        \n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        (oldh, oldw, oldc) = self.env.observation_space.shape\n",
    "        ratio = 2\n",
    "        newshape = (oldw//ratio, oldh//ratio)\n",
    "        \n",
    "        downsampled_gray_frame = cv2.resize(gray_frame, newshape, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        grayscale_downsample_crop_frame = downsampled_gray_frame[20:100,:]\n",
    "        \n",
    "        return grayscale_downsample_crop_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a random agent on the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Agent():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self):\n",
    "        return env_wrap.env.action_space.sample()  # sample random action\n",
    "\n",
    "random_agent = Random_Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9 sum_of_rewards_for_episode: 0.0\n",
      "episode: 9 sum_of_rewards_for_episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "max_time_steps = 200\n",
    "env_wrap = Env_Wrap(4,4)\n",
    "\n",
    "#run the random agent in the environment for N episodes\n",
    "for episode in range(N):\n",
    "    reward_sum = 0\n",
    "    next_state = env_wrap.env.reset()\n",
    "    for i in range(max_time_steps):\n",
    "        action = random_agent.select_action()\n",
    "        next_state, reward, terminal, info = env_wrap.step(action)\n",
    "        reward_sum += reward\n",
    "        #env_wrap.render()\n",
    "        if terminal:\n",
    "            clear_output(wait=True)\n",
    "            time.sleep(0.2)\n",
    "            print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum)\n",
    "            break\n",
    "print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum)\n",
    "#env_wrap.env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for a given state: 4\n",
      "Number of actions for a given state: 4\n"
     ]
    }
   ],
   "source": [
    "state_dim = 4\n",
    "action_dim = env_wrap.env.action_space.n\n",
    "\n",
    "print('Number of observations for a given state:', state_dim)\n",
    "print('Number of actions for a given state:', action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Larger network used in nature paper \n",
    "class Q_Network(nn.Module):\n",
    "    def __init__(self, state_dim , action_dim):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.x_layer = nn.Conv2d(state_dim,32,8,stride=4) #convolves 32 filters of 8 x 8 with stride 4\n",
    "        nn.init.kaiming_normal_(self.x_layer.weight, mode='fan_in', nonlinearity='relu') #He (2015) initialization\n",
    "        self.h_layer1 = nn.Conv2d(32,64,4,stride=2) #convolves 64 filters of 4 x 4 with stride 2\n",
    "        nn.init.kaiming_normal_(self.h_layer1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.h_layer2 = nn.Conv2d(64,64,3,stride=1) #convolves 64 filters of 3 x 3 with stride 1\n",
    "        nn.init.kaiming_normal_(self.h_layer2.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.h_layer3 = nn.Linear(6*6*64,512) #512 rectifier units\n",
    "        nn.init.kaiming_normal_(self.h_layer3.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.y_layer = nn.Linear(512, action_dim) #fully-connected linear layer with a single output for each action\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x/255.0\n",
    "        x = F.relu(self.x_layer(x))\n",
    "        x = F.relu(self.h_layer1(x))\n",
    "        x = F.relu(self.h_layer2(x))\n",
    "        x = F.relu(self.h_layer3(x.view(-1,6*6*64)))\n",
    "        x = self.y_layer(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of our q_network given a state input:  tensor([[-0.0152,  0.1620, -0.0772,  0.1325]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Test network gives the correct output\n",
    "qnet = Q_Network(state_dim, action_dim)\n",
    "state = torch.from_numpy(env_wrap.reset()).float().view(-1,4,80,80)\n",
    "q_values = qnet(state)\n",
    "print('output of our q_network given a state input: ', q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SumTree(object):\n",
    "\n",
    "    def __init__(self, replay_size):\n",
    "\n",
    "        self.replay_size = replay_size\n",
    "        self.priority_size = 2*replay_size - 1\n",
    "        self.priority = [0.0 for _ in range(2*replay_size-1)]\n",
    "        #self.priority = torch.zeros(self.priority_size, dtype=torch.float).cuda()\n",
    "        self.priority[0] = 1.0\n",
    "        #self.memory = [0 for _ in range(replay_size)]\n",
    "        self.states_memory = [0 for _ in range(replay_size)]\n",
    "        self.next_states_memory = [0 for _ in range(replay_size)]\n",
    "        self.actions_memory = [0 for _ in range(replay_size)]\n",
    "        self.rewards_memory = [0 for _ in range(replay_size)]\n",
    "        self.terminals_memory = [0 for _ in range(replay_size)]\n",
    "        self.cursor = 0\n",
    "        self.cur_size = 0\n",
    "\n",
    "    def sum_up(self, index, delta):\n",
    "\n",
    "        parent_ind = (index - 1) // 2\n",
    "\n",
    "        self.priority[parent_ind] += delta\n",
    "\n",
    "        if not self.is_root(parent_ind):\n",
    "            self.sum_up(parent_ind, delta)\n",
    "\n",
    "    def update_priority(self, index, new_priority):\n",
    "\n",
    "        delta = new_priority - self.priority[index]\n",
    "\n",
    "        self.priority[index] = new_priority\n",
    "\n",
    "        self.sum_up(index, delta)\n",
    "\n",
    "    def add_memory(self, state, next_state, action, reward, terminal, priority):\n",
    "\n",
    "        #self.memory[self.cursor] = data\n",
    "        \n",
    "        self.states_memory[self.cursor] = state\n",
    "        self.next_states_memory[self.cursor] = next_state\n",
    "        self.actions_memory[self.cursor] = action\n",
    "        self.rewards_memory[self.cursor] = reward\n",
    "        self.terminals_memory[self.cursor] = terminal\n",
    "\n",
    "        priority_index = self.cursor + (self.replay_size - 1)\n",
    "        #self.priority[priority_index] = priority\n",
    "        self.update_priority(priority_index, priority)\n",
    "\n",
    "        self.cursor = (self.cursor + 1) % self.replay_size\n",
    "\n",
    "        if self.cur_size < self.replay_size:\n",
    "            self.cur_size += 1 \n",
    "\n",
    "    def is_root(self, index):\n",
    "\n",
    "        if index == 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def priority_total(self):\n",
    "\n",
    "        return self.priority[0]\n",
    "\n",
    "    def get_priority(self, index, sample):\n",
    "\n",
    "        left_child = 2*index + 1\n",
    "        right_child = 2*index + 2\n",
    "\n",
    "        if left_child >= self.priority_size:\n",
    "\n",
    "            return index\n",
    "\n",
    "        elif sample <= self.priority[left_child]:\n",
    "\n",
    "            return self.get_priority(left_child, sample)\n",
    "\n",
    "        else:\n",
    "\n",
    "            return self.get_priority(right_child, sample - self.priority[left_child])\n",
    "\n",
    "    def get(self, sample):\n",
    "\n",
    "        priority_index = self.get_priority(0, sample)\n",
    "\n",
    "        memory_index = priority_index - self.replay_size + 1\n",
    "\n",
    "        #return priority_index, self.priority[priority_index], self.memory[memory_index]\n",
    "        return priority_index, memory_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrioritisedMemory(object):\n",
    "\n",
    "    def __init__(self, alpha, beta, beta_end, epsilon, num_steps, replay_size):\n",
    "\n",
    "        self.alpha = alpha\n",
    "        self.beta_start = beta\n",
    "        self.beta_end = beta_end\n",
    "        self.beta = beta \n",
    "        self.epsilon = epsilon\n",
    "        self.num_steps = num_steps\n",
    "\n",
    "        self.memory = SumTree(replay_size)\n",
    "        self.replay_size = replay_size\n",
    "\n",
    "    def proprotional_priority(self, td_error):\n",
    "\n",
    "        return torch.pow((torch.abs(td_error) + self.epsilon),self.alpha)\n",
    "\n",
    "    def add_memory(self, td_error, state, next_state, action, reward, terminal):\n",
    "\n",
    "        priority = self.proprotional_priority(td_error)\n",
    "\n",
    "        self.memory.add_memory(state, next_state, action, reward, terminal, priority)\n",
    "\n",
    "        self.beta = np.min([1.0, self.beta + (self.beta_end-self.beta_start)/self.num_steps])\n",
    "\n",
    "    def update_priority(self, index, td_error):\n",
    "\n",
    "        new_priority = self.proprotional_priority(td_error)\n",
    "        self.memory.update_priority(index, new_priority)\n",
    "\n",
    "    def minibatch_sample(self, minibatch_size):\n",
    "\n",
    "        priority_indexes = []\n",
    "        memory_indexes = []\n",
    "\n",
    "        interval = self.memory.priority_total().item()/minibatch_size\n",
    "        #print(interval)\n",
    "\n",
    "        for i in range(minibatch_size):\n",
    "\n",
    "            sample = np.random.uniform(i*interval, (i+1)*interval)\n",
    "\n",
    "            priority_index, memory_index = self.memory.get(sample)\n",
    "\n",
    "            priority_indexes.append(priority_index)\n",
    "            memory_indexes.append(memory_index)\n",
    "            \n",
    "        states = torch.stack(itemgetter(*memory_indexes)(self.memory.states_memory))\n",
    "        next_states = torch.stack(itemgetter(*memory_indexes)(self.memory.next_states_memory))\n",
    "        actions = torch.stack(itemgetter(*memory_indexes)(self.memory.actions_memory))\n",
    "        rewards = torch.stack(itemgetter(*memory_indexes)(self.memory.rewards_memory))\n",
    "        terminals = torch.stack(itemgetter(*memory_indexes)(self.memory.terminals_memory))\n",
    "        priorities = torch.stack(itemgetter(*priority_indexes)(self.memory.priority))\n",
    "\n",
    "        sampling_probabilities = priorities/self.memory.priority_total()\n",
    "        importance_weights = torch.pow(self.memory.replay_size * sampling_probabilities, -self.beta)\n",
    "        importance_weights /= torch.max(importance_weights)\n",
    "\n",
    "        return priority_indexes, states, next_states, actions, rewards, terminals, importance_weights \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "    def __init__(self, state_dim, action_dim, gamma, \n",
    "                 alpha, beta, beta_end, epsilon, num_steps, \n",
    "                 replay_size, tau, learning_rate, minibatch_size):\n",
    "        \n",
    "        self.qnet = Q_Network(state_dim, action_dim)\n",
    "        self.qnet_target = copy.deepcopy(self.qnet)\n",
    "        self.discount_factor = gamma\n",
    "        self.MSELoss_function = nn.MSELoss()\n",
    "        self.replay_buffer = PrioritisedMemory(alpha, beta, beta_end, epsilon, num_steps, replay_size)\n",
    "        self.tau = tau\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.qnet.cuda()\n",
    "            self.qnet_target.cuda()\n",
    "            print('Running model on GPU:',torch.cuda.get_device_name(torch.cuda.current_device()),'!')\n",
    "        \n",
    "        self.qnet_optim = torch.optim.Adam( self.qnet.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            return env_wrap.env.action_space.sample()  # choose random action\n",
    "        else:\n",
    "            network_output_to_numpy = (self.qnet(state)).cpu().data.numpy()\n",
    "            #network_output = self.qnet(state)\n",
    "            return np.argmax(network_output_to_numpy)  # choose greedy action\n",
    "            \n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals, importance_weights, priority_indexes):\n",
    "        qnetsa = torch.gather(self.qnet(state), dim=1, index=action.long())\n",
    "        \n",
    "        #YDoubleDQN_t ≡ R_t+1 + γ * Q(S_t+1, argmax_aQ(S_t+1, a; θ_t), θ^−_t).\n",
    "        \n",
    "        _,qnetsa_next_state_action_argmax = torch.max(self.qnet(next_state), dim=1, keepdim=True)\n",
    "        qtargetsa_next_state_argmax_qnet = torch.gather(self.qnet_target(next_state), 1, qnetsa_next_state_action_argmax)\n",
    "        not_terminals = 1 - terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * qtargetsa_next_state_argmax_qnet \n",
    "        td_error = (qsa_next_target - qnetsa).detach()\n",
    "        \n",
    "        #update transition priority\n",
    "        for i in range(self.minibatch_size):\n",
    "            priority_index = priority_indexes[i]\n",
    "            self.replay_buffer.update_priority(priority_index, td_error[i])\n",
    "        \n",
    "        q_network_loss = (importance_weights.detach() * self.MSELoss_function(qnetsa, qsa_next_target.detach())).mean()\n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        #Gradient Clipping between (-1, 1)\n",
    "        for param in self.qnet.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.qnet_optim.step()\n",
    "        \n",
    "        return q_network_loss\n",
    "        \n",
    "    def update(self):\n",
    "        priority_indexes, states, next_states, actions, rewards, terminals, importance_weights  = self.replay_buffer.minibatch_sample(self.minibatch_size)\n",
    "        \n",
    "        loss = self.update_Q_Network(states, next_states, actions, rewards, terminals, importance_weights, priority_indexes)\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode: 2885 \n",
      "Current episode reward: 16.0 \n",
      "Average loss: 0.013756162468809634 \n",
      "Current total steps: 1099636 \n",
      "Greatest reward: 241.0 \n",
      "Current epsilon: 0.010044318915702868\n"
     ]
    }
   ],
   "source": [
    "#Learning parameters\n",
    "total_time_steps = 1100000 #Number of steps to train on\n",
    "max_time_steps = 5000 #Max number of step in each episode if terminal state not reached\n",
    "gamma = 0.99 #Discount factor\n",
    "learning_rate = 0.00025 #Gradient step size, they used 0.00025/4 in the paper  \n",
    "                        #but use 0.00025 for fairer comparison with vanilla DQN\n",
    "learning_starts = 100000 #Model starts learning after x transitions\n",
    "update_freq = 4 #Minibatch update frequency in number of steps\n",
    "\n",
    "#Exploration parametrs\n",
    "epsilon_start = 1.0 #Starting epsilon value\n",
    "epsilon_mid = 0.1 #Epsion value after some training\n",
    "epsilon_final = 0.01 #Final epsiolon value\n",
    "epsilon_decay_length1 = 100000 #total_time_steps//10 #Number of episodes to decay epsilon over, 10% total time steps\n",
    "epsilon_decay_length2 = total_time_steps - epsilon_decay_length1 -learning_starts\n",
    "eps = epsilon_start\n",
    "\n",
    "#Target update frequency\n",
    "target_update = 10000 #Target network update frequency (number of steps)\n",
    "tau = 0.001 #Soft target network update\n",
    "\n",
    "#Prioritised Memory Parameters\n",
    "alpha = 0.6\n",
    "beta = 0.4\n",
    "beta_end = 1.0 \n",
    "epsilon = 0.01 \n",
    "replay_size = 100000 #Number of transitions to store in replay memory, 10% total steps\n",
    "minibatch_size = 32 #Number of samples in minibatch update, 32 used in atari DQN paper\n",
    "\n",
    "#Create agent object\n",
    "agent = DQNAgent(state_dim, action_dim, gamma, \n",
    "                 alpha, beta, beta_end, epsilon, total_time_steps, \n",
    "                 replay_size, tau, learning_rate, minibatch_size)\n",
    "\n",
    "#Loop parameters\n",
    "reward_sums = []\n",
    "best_reward = -np.inf\n",
    "total_steps = 0\n",
    "episode = 0\n",
    "reward_sum = 0\n",
    "eps = epsilon_start\n",
    "save_freq = 100000 #Save checkpoint every x steps\n",
    "\n",
    "#Loss moving average\n",
    "avg_loss = 0\n",
    "avg_losses = []\n",
    "loss_list_len = 1000\n",
    "loss_list = [0.0]*loss_list_len\n",
    "loss_pos = 0\n",
    "avg_episode_losses = []\n",
    "\n",
    "while total_steps < total_time_steps:\n",
    "    episode += 1\n",
    "    lives = 5\n",
    "    state = torch.ByteTensor(env_wrap.reset()).cuda()\n",
    "    clear_output(wait=True)\n",
    "    print('Current episode:',episode,\n",
    "          '\\nCurrent episode reward:', reward_sum,\n",
    "          '\\nAverage loss:', avg_loss,\n",
    "          '\\nCurrent total steps:',total_steps, \n",
    "          '\\nGreatest reward:', best_reward,\n",
    "          '\\nCurrent epsilon:', eps)\n",
    "    reward_sum = 0\n",
    "    losses = []\n",
    "\n",
    "    for i in range(max_time_steps):\n",
    "        \n",
    "        total_steps += 1\n",
    "        action = agent.epsilon_greedy_action(state.view(-1,4,80,80), eps)\n",
    "        next_state, reward, terminal, info = env_wrap.step(action)\n",
    "        \n",
    "        #Convert to pytorch tensor\n",
    "        next_state = torch.ByteTensor(next_state).cuda()\n",
    "        action = torch.ByteTensor([action]).cuda()\n",
    "        t_reward = torch.ByteTensor([reward]).cuda()\n",
    "        terminal = torch.ByteTensor([terminal]).cuda()\n",
    "        \n",
    "        #Compute dt_error\n",
    "        qnetsa = torch.gather(agent.qnet(state.view(-1,4,80,80)), dim=1, index=action.view(-1,1).long())\n",
    "        _,qnetsa_next_state_action_argmax = torch.max(agent.qnet(next_state.view(-1,4,80,80)), dim=1, keepdim=True)\n",
    "        qtargetsa_next_state_argmax_qnet = torch.gather(agent.qnet_target(next_state.view(-1,4,80,80)), 1, qnetsa_next_state_action_argmax)\n",
    "        not_terminal = 1 - terminal\n",
    "        qsa_next_target = t_reward + not_terminal * agent.discount_factor * qtargetsa_next_state_argmax_qnet \n",
    "        td_error = (qsa_next_target - qnetsa).flatten().detach()\n",
    "        \n",
    "        if lives != info['lives']:\n",
    "            agent.replay_buffer.add_memory(td_error , state, next_state, action , t_reward, torch.ByteTensor([True]).cuda())\n",
    "            lives = info['lives']\n",
    "        else:\n",
    "            agent.replay_buffer.add_memory(td_error , state, next_state, action, t_reward, terminal)\n",
    "                    \n",
    "        state = next_state\n",
    "        \n",
    "        reward_sum += reward\n",
    "        \n",
    "        #Update network if learning has started and update frequency reached\n",
    "        if total_steps > learning_starts and total_steps % update_freq == 0:\n",
    "            loss = agent.update()\n",
    "            loss_list[loss_pos] = loss\n",
    "            loss_pos = (loss_pos + 1)%loss_list_len\n",
    "            avg_loss = sum(loss_list)/loss_list_len\n",
    "            avg_losses.append(avg_loss)\n",
    "            losses.append(loss)\n",
    "        \n",
    "        #Update target network if target update freqency reached\n",
    "        if total_steps % target_update == 0:\n",
    "            agent.qnet_target.load_state_dict(agent.qnet.state_dict())\n",
    "            \n",
    "        #Decay epsilon if total steps is less than decay length\n",
    "        if total_steps > learning_starts:\n",
    "            if (epsilon_decay_length1 + learning_starts) > total_steps:\n",
    "                eps -= (epsilon_start-epsilon_mid)/epsilon_decay_length1\n",
    "            else:\n",
    "                eps -= (epsilon_mid-epsilon_final)/epsilon_decay_length2\n",
    "            \n",
    "        #Periodically save the model incase crash\n",
    "        if total_steps % save_freq == 0:\n",
    "            torch.save({\n",
    "            'epoch': total_steps,\n",
    "            'model_state_dict': agent.qnet.state_dict(),\n",
    "            'optimizer_state_dict': agent.qnet_optim.state_dict()\n",
    "            }, 'checkpoint.pth')\n",
    "        \n",
    "        if terminal:\n",
    "            #clear_output(wait=True)\n",
    "            #print('Current total steps:', total_steps, 'Rewards for episode:', reward_sum)\n",
    "            break\n",
    "            \n",
    "    if reward_sum > best_reward:\n",
    "        best_reward = reward_sum\n",
    "    \n",
    "    reward_sums.append(reward_sum)\n",
    "    \n",
    "    if total_steps > learning_starts:\n",
    "        if len(losses) == 0:\n",
    "            #prevent divide by zero error\n",
    "            pass\n",
    "        else:\n",
    "            avg_episode_losses.append(sum(losses)/len(losses))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(agent.qnet.state_dict(), 'PDDQN_model_75K_memory.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Episode')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot reward per episode\n",
    "plt.plot(reward_sums)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch (10 Episodes)')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot average reward\n",
    "reward_sums_av = []\n",
    "for i in range(0,len(reward_sums)-100,10):\n",
    "    reward_sums_av.append(sum(reward_sums[i:i+100])/100)\n",
    "    \n",
    "plt.plot(reward_sums_av)\n",
    "plt.ylabel('Average Reward per 100 Episodes')\n",
    "plt.xlabel('Epoch (10 Episodes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play Breakout using learnt agent\n",
    "terminal =  False\n",
    "state = env_wrap.reset()\n",
    "total_reward = 0.0\n",
    "num_actions = 0\n",
    "\n",
    "while not terminal:\n",
    "    \n",
    "    action = agent.epsilon_greedy_action( torch.from_numpy(state).float().view(-1,4,80,80).cuda() , 0.01)\n",
    "    next_state, reward, terminal, _ = env_wrap.step(action)\n",
    "    num_actions += 1\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    time.sleep(0.05)\n",
    "    env_wrap.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1464 24.0\n"
     ]
    }
   ],
   "source": [
    "print(num_actions, total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
