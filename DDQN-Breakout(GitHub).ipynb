{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double Deep Q-Learning for Atari Breakout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Many imports\n",
    "import retro\n",
    "import numpy as np\n",
    "from queue import Queue\n",
    "import cv2\n",
    "import itertools\n",
    "from retro.examples.discretizer import Discretizer\n",
    "from IPython.display import clear_output, display\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "from operator import itemgetter \n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Env_Wrap:\n",
    "    def __init__(self, state_len, num_frame_skip):\n",
    "        #Initiate Environment Wrapper\n",
    "        self.env = retro.RetroEnv(game='Breakout-Atari2600')\n",
    "        \n",
    "        # Define action space in terms of valid combinations of button presses\n",
    "        combos = [['BUTTON'],['LEFT'],['RIGHT'],[]]\n",
    "        self.action_space_size = len(combos)\n",
    "        self.env = Discretizer(self.env, combos=combos)\n",
    "        \n",
    "        #Number of frames to skip\n",
    "        self.num_frame_skip = num_frame_skip \n",
    "        self.num_frame_skip_1 = num_frame_skip - 3\n",
    "        \n",
    "        #Number of frames in each state\n",
    "        self.state_len = state_len\n",
    "        \n",
    "        _ = self.reset()\n",
    "        \n",
    "    def reset(self):\n",
    "        #Frame buffer\n",
    "        self.frame_buffer = np.zeros((80,80,2))\n",
    "        \n",
    "        #Hold the previous 4 states\n",
    "        self.state_queue = Queue(maxsize = self.state_len)\n",
    "        #Fill state queue with empty states\n",
    "        for i in range(self.state_len):\n",
    "            self.state_queue.put(np.zeros((80,80)))\n",
    "        \n",
    "        self.env.reset()\n",
    "        #Take NOOP action \n",
    "        for _ in range(15):\n",
    "            state,_,_,_ = self.step(3)\n",
    "        \n",
    "        return state\n",
    "        \n",
    "    def step(self, action):\n",
    "        \n",
    "        next_step, reward, terminal, info = self.frame_skip(action)\n",
    "        _ = self.state_queue.get()\n",
    "        self.state_queue.put(next_step)\n",
    "        state = np.stack(list(self.state_queue.queue)).astype(np.uint8)\n",
    "        \n",
    "        return state, reward, terminal, info\n",
    "    \n",
    "    def render(self):\n",
    "        self.env.render()\n",
    "        \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "    \n",
    "    def frame_skip(self, action):\n",
    "        \n",
    "        total_reward = 0.0\n",
    "        for skip in range(self.num_frame_skip):\n",
    "        \n",
    "            if skip > self.num_frame_skip_1:\n",
    "                obs, rew, done, info = self.env.step(action)\n",
    "                self.frame_buffer[:,:,skip-(self.num_frame_skip-2)] = self.grayscale_downsample_crop(obs)\n",
    "            \n",
    "            else:\n",
    "                obs, rew, done, info = self.env.step(action)\n",
    "                \n",
    "            total_reward += rew\n",
    "        \n",
    "        max_pool = np.maximum(self.frame_buffer[:,:,0],self.frame_buffer[:,:,1])\n",
    "        \n",
    "        return max_pool, total_reward, done, info\n",
    "    \n",
    "    def grayscale_downsample_crop(self, frame):\n",
    "        #Frames are coverted to gray scale, downsampled by 50% and cropped to 80x80 \n",
    "        \n",
    "        gray_frame = cv2.cvtColor(frame, cv2.COLOR_RGB2GRAY)\n",
    "        \n",
    "        (oldh, oldw, oldc) = self.env.observation_space.shape\n",
    "        ratio = 2\n",
    "        newshape = (oldw//ratio, oldh//ratio)\n",
    "        \n",
    "        downsampled_gray_frame = cv2.resize(gray_frame, newshape, interpolation=cv2.INTER_AREA)\n",
    "        \n",
    "        grayscale_downsample_crop_frame = downsampled_gray_frame[20:100,:]\n",
    "        \n",
    "        return grayscale_downsample_crop_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run a random agent on the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Agent():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def select_action(self):\n",
    "        return env_wrap.env.action_space.sample()  # sample random action\n",
    "\n",
    "random_agent = Random_Agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode: 9 sum_of_rewards_for_episode: 0.0\n",
      "episode: 9 sum_of_rewards_for_episode: 0.0\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "max_time_steps = 200\n",
    "env_wrap = Env_Wrap(4,4)\n",
    "\n",
    "#run the random agent in the environment for N episodes\n",
    "for episode in range(N):\n",
    "    reward_sum = 0\n",
    "    next_state = env_wrap.env.reset()\n",
    "    for i in range(max_time_steps):\n",
    "        action = random_agent.select_action()\n",
    "        next_state, reward, terminal, info = env_wrap.step(action)\n",
    "        reward_sum += reward\n",
    "        #env_wrap.render()\n",
    "        if terminal:\n",
    "            clear_output(wait=True)\n",
    "            time.sleep(0.2)\n",
    "            print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum)\n",
    "            break\n",
    "print('episode:', episode, 'sum_of_rewards_for_episode:', reward_sum)\n",
    "#env_wrap.env.render(close=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Constructing the Q Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of observations for a given state: 4\n",
      "Number of actions for a given state: 4\n"
     ]
    }
   ],
   "source": [
    "state_dim = 4\n",
    "action_dim = env_wrap.env.action_space.n\n",
    "\n",
    "print('Number of observations for a given state:', state_dim)\n",
    "print('Number of actions for a given state:', action_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Larger network used in nature paper \n",
    "class Q_Network(nn.Module):\n",
    "    def __init__(self, state_dim , action_dim):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.x_layer = nn.Conv2d(state_dim,32,8,stride=4) #convolves 32 filters of 8 x 8 with stride 4\n",
    "        nn.init.kaiming_normal_(self.x_layer.weight, mode='fan_in', nonlinearity='relu') #He (2015) initialization\n",
    "        self.h_layer1 = nn.Conv2d(32,64,4,stride=2) #convolves 64 filters of 4 x 4 with stride 2\n",
    "        nn.init.kaiming_normal_(self.h_layer1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.h_layer2 = nn.Conv2d(64,64,3,stride=1) #convolves 64 filters of 3 x 3 with stride 1\n",
    "        nn.init.kaiming_normal_(self.h_layer2.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.h_layer3 = nn.Linear(6*6*64,512) #512 rectifier units\n",
    "        nn.init.kaiming_normal_(self.h_layer3.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.y_layer = nn.Linear(512, action_dim) #fully-connected linear layer with a single output for each action\n",
    "\n",
    "    def forward(self, state):\n",
    "        state = state/255.0\n",
    "        xh = F.relu(self.x_layer(state))\n",
    "        hh1 = F.relu(self.h_layer1(xh))\n",
    "        hh2 = F.relu(self.h_layer2(hh1))\n",
    "        hh2 = hh2.view(-1,6*6*64)\n",
    "        hh3 = F.relu(self.h_layer3(hh2))\n",
    "        state_action_values = self.y_layer(hh3)\n",
    "        return state_action_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smaller network used in Atari DQN paper\n",
    "'''\n",
    "class Q_Network(nn.Module):\n",
    "    def __init__(self, state_dim , action_dim):\n",
    "        super(Q_Network, self).__init__()\n",
    "        self.x_layer = nn.Conv2d(state_dim,16,8,stride=4)\n",
    "        nn.init.kaiming_normal_(self.x_layer.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.h_layer1 = nn.Conv2d(16,32,4,stride=2)\n",
    "        nn.init.kaiming_normal_(self.h_layer1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.h_layer2 = nn.Linear(8*8*32,256)\n",
    "        nn.init.kaiming_normal_(self.h_layer2.weight, mode='fan_in', nonlinearity='relu')\n",
    "        self.y_layer = nn.Linear(256, action_dim)\n",
    "\n",
    "    def forward(self, state):\n",
    "        xh = F.relu(self.x_layer(state))\n",
    "        hh1 = F.relu(self.h_layer1(xh))\n",
    "        hh1 = hh1.view(-1,8*8*32)\n",
    "        hh2 = F.relu(self.h_layer2(hh1))\n",
    "        state_action_values = self.y_layer(hh2)\n",
    "        return state_action_values\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output of our q_network given a state input:  tensor([[ 0.0593,  0.4211, -0.0164, -0.0734]], grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#Test network gives the correct output\n",
    "qnet = Q_Network(state_dim, action_dim)\n",
    "state = torch.from_numpy(env_wrap.reset()).float().view(-1,4,80,80)\n",
    "q_values = qnet(state)\n",
    "print('output of our q_network given a state input: ', q_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the Replay Buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer(object):\n",
    "    def __init__(self, buffer_len):\n",
    "        self.buffer_len = buffer_len\n",
    "        self.buffer_states = []\n",
    "        self.buffer_next_states = []\n",
    "        self.buffer_actions = []\n",
    "        self.buffer_rewards = []\n",
    "        self.buffer_terminals = []\n",
    "        self.buffer_size = 0\n",
    "        self.cur_pos = 0\n",
    "\n",
    "    def add_to_buffer(self, data):\n",
    "        #data must be of the form (state,next_state,action,reward,terminal)\n",
    "        \n",
    "        if self.buffer_size < self.buffer_len:\n",
    "            self.buffer_size += 1\n",
    "            self.buffer_states.append(data[0])\n",
    "            self.buffer_next_states.append(data[1])\n",
    "            self.buffer_actions.append(data[2]) \n",
    "            self.buffer_rewards.append(data[3])\n",
    "            self.buffer_terminals.append(data[4]) \n",
    "        \n",
    "        else:\n",
    "            self.buffer_states[self.cur_pos] = data[0]\n",
    "            self.buffer_next_states[self.cur_pos] = data[1]\n",
    "            self.buffer_actions[self.cur_pos] = data[2]\n",
    "            self.buffer_rewards[self.cur_pos] = data[3]\n",
    "            self.buffer_terminals[self.cur_pos] = data[4]\n",
    "            self.cur_pos = (self.cur_pos + 1) % self.buffer_len\n",
    "        \n",
    "    def sample_minibatch(self,minibatch_length):\n",
    "        \n",
    "        if minibatch_length > self.buffer_size:\n",
    "            #Return entire buffer\n",
    "            return torch.FloatTensor(self.buffer_states).cuda(), \\\n",
    "                    torch.FloatTensor(self.buffer_next_states).cuda(), \\\n",
    "                    torch.FloatTensor(self.buffer_actions).cuda(), \\\n",
    "                    torch.FloatTensor(self.buffer_rewards).cuda(), \\\n",
    "                    torch.FloatTensor(self.buffer_terminals).cuda()\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            samples_ind = np.random.randint(0,self.buffer_size,minibatch_length)\n",
    "        \n",
    "            return torch.FloatTensor(itemgetter(*samples_ind)(self.buffer_states)).cuda(), \\\n",
    "                    torch.FloatTensor(itemgetter(*samples_ind)(self.buffer_next_states)).cuda(), \\\n",
    "                    torch.FloatTensor(itemgetter(*samples_ind)(self.buffer_actions)).cuda(), \\\n",
    "                    torch.FloatTensor(itemgetter(*samples_ind)(self.buffer_rewards)).cuda(), \\\n",
    "                    torch.FloatTensor(itemgetter(*samples_ind)(self.buffer_terminals)).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DQN Agent Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQNAgent(object):\n",
    "    def __init__(self, state_dim, action_dim, gamma, buffer_size, tau, learning_rate, minibatch_size):\n",
    "        self.qnet = Q_Network(state_dim, action_dim)\n",
    "        self.qnet_target = copy.deepcopy(self.qnet)\n",
    "        self.discount_factor = gamma\n",
    "        #self.MSELoss_function = nn.MSELoss()\n",
    "        self.MSELoss_function = nn.SmoothL1Loss() #Huber Loss instead of MSE loss\n",
    "        self.replay_buffer = ReplayBuffer(buffer_size)\n",
    "        self.tau = tau\n",
    "        self.minibatch_size = minibatch_size\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.qnet.cuda()\n",
    "            self.qnet_target.cuda()\n",
    "            print('Running model on GPU:',torch.cuda.get_device_name(torch.cuda.current_device()),'!')\n",
    "        \n",
    "        self.qnet_optim = torch.optim.Adam( self.qnet.parameters(), lr=learning_rate)\n",
    "    \n",
    "    def epsilon_greedy_action(self, state, epsilon):\n",
    "        if np.random.uniform(0, 1) < epsilon:\n",
    "            return env_wrap.env.action_space.sample()  # choose random action\n",
    "        else:\n",
    "            network_output_to_numpy = self.qnet(state).cpu().data.numpy()\n",
    "            #network_output = self.qnet(state)\n",
    "            return np.argmax(network_output_to_numpy)  # choose greedy action\n",
    "            \n",
    "    def update_Q_Network(self, state, next_state, action, reward, terminals):\n",
    "        qnetsa = torch.gather(self.qnet(state), dim=1, index=action.long())\n",
    "        \n",
    "        #YDoubleDQN_t ≡ R_t+1 + γ * Q(S_t+1, argmax_aQ(S_t+1, a; θ_t), θ^−_t).\n",
    "        #https://arxiv.org/abs/1509.06461\n",
    "        \n",
    "        _,qnetsa_next_state_action_argmax = torch.max(self.qnet(next_state), dim=1, keepdim=True)\n",
    "        qtargetsa_next_state_argmax_qnet = torch.gather(self.qnet_target(next_state), 1, qnetsa_next_state_action_argmax)\n",
    "        not_terminals = 1 - terminals\n",
    "        qsa_next_target = reward + not_terminals * self.discount_factor * qtargetsa_next_state_argmax_qnet \n",
    "        q_network_loss = self.MSELoss_function(qnetsa, qsa_next_target.detach())\n",
    "        self.qnet_optim.zero_grad()\n",
    "        q_network_loss.backward()\n",
    "        \n",
    "        #Gradient Clipping between (-1, 1)\n",
    "        for param in self.qnet.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "            \n",
    "        self.qnet_optim.step()\n",
    "        \n",
    "        return q_network_loss\n",
    "        \n",
    "    def update(self):\n",
    "        states, next_states, actions, rewards, terminals = self.replay_buffer.sample_minibatch(self.minibatch_size)\n",
    "        loss = self.update_Q_Network(states, next_states, actions, rewards, terminals)\n",
    "        \n",
    "        return loss.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current episode: 2156 \n",
      "Current episode reward: 0 \n",
      "Average loss: 0.012266043293755502 \n",
      "Current total steps: 999869 \n",
      "Greatest reward: 322.0 \n",
      "Current epsilon: 0.010022764704437373\n"
     ]
    }
   ],
   "source": [
    "#Learning parameters\n",
    "total_time_steps = 1000000 #Number of steps to train on\n",
    "max_time_steps = 5000 #Max number of step in each episode if terminal state not reached\n",
    "gamma = 0.99 #Discount factor\n",
    "buffer_size = 100000 #Number of transitions to store in replay memory, 10% total steps\n",
    "minibatch_size = 32 #Number of samples in minibatch update, 32 used in atari DQN paper\n",
    "tau = 0.001 #Soft target network update\n",
    "learning_rate = 0.00025 #Gradient step size\n",
    "target_update = 10000 #Target network update frequency (number of steps)\n",
    "learning_starts = 5000 #Model starts learning after x transitions \n",
    "update_freq = 4 #Minibatch update frequency in number of steps\n",
    "\n",
    "#Epsilon decay parameters\n",
    "epsilon_start = 1.0 #Starting epsilon value\n",
    "epsilon_mid = 0.1 #Epsion value after some training\n",
    "epsilon_final = 0.01 #Final epsiolon value\n",
    "epsilon_decay_length1 = 100000 #total_time_steps//10 #Number of episodes to decay epsilon over, 10% total time steps\n",
    "epsilon_decay_length2 = total_time_steps - epsilon_decay_length1 - 50000\n",
    "eps = epsilon_start\n",
    "\n",
    "agent = DQNAgent(state_dim, action_dim, gamma, buffer_size, tau, learning_rate, minibatch_size)\n",
    "\n",
    "#Loop variables\n",
    "total_steps = 0\n",
    "episode = 0\n",
    "save_freq = 50000 #Save checkpoint every x steps\n",
    "reward_sums = [] #Stores the undiscounted sum of rewards per episode\n",
    "best_reward = -np.inf\n",
    "\n",
    "\n",
    "#Loss moving average\n",
    "avg_loss = 0\n",
    "avg_losses = []\n",
    "loss_list_len = 1000\n",
    "loss_list = [0.0]*loss_list_len\n",
    "loss_pos = 0\n",
    "avg_episode_losses = [] #Stores the average loss per episode\n",
    "\n",
    "while total_steps < total_time_steps:\n",
    "    episode += 1\n",
    "    lives = 5\n",
    "    state = env_wrap.reset()\n",
    "    clear_output(wait=True)\n",
    "    print('Current episode:',episode,\n",
    "          '\\nCurrent episode reward:', reward_sum,\n",
    "          '\\nAverage loss:', avg_loss,\n",
    "          '\\nCurrent total steps:',total_steps, \n",
    "          '\\nGreatest reward:', best_reward,\n",
    "          '\\nCurrent epsilon:', eps)\n",
    "    reward_sum = 0\n",
    "    losses = []\n",
    "\n",
    "    for i in range(max_time_steps):\n",
    "        \n",
    "        total_steps += 1\n",
    "        action = agent.epsilon_greedy_action( torch.from_numpy(state).float().view(-1,4,80,80).cuda() , eps)\n",
    "        next_state, reward, terminal, info = env_wrap.step(action)\n",
    "        \n",
    "        if lives != info['lives']:\n",
    "            agent.replay_buffer.add_to_buffer( (state,next_state,[action],[reward],[True]) )\n",
    "            lives = info['lives']\n",
    "        else:\n",
    "            agent.replay_buffer.add_to_buffer( (state,next_state,[action],[reward],[terminal]) )\n",
    "        \n",
    "        state = next_state\n",
    "        \n",
    "        reward_sum += reward\n",
    "        \n",
    "        #Update network if learning has started and update frequency reached\n",
    "        if total_steps > learning_starts and total_steps % update_freq == 0:\n",
    "            loss = agent.update()\n",
    "            loss_list[loss_pos] = loss\n",
    "            loss_pos = (loss_pos + 1)%loss_list_len\n",
    "            avg_loss = sum(loss_list)/loss_list_len\n",
    "            avg_losses.append(avg_loss)\n",
    "            losses.append(loss)\n",
    "        \n",
    "        #Update target network if target update freqency reached\n",
    "        if total_steps % target_update == 0:\n",
    "            agent.qnet_target.load_state_dict(agent.qnet.state_dict())\n",
    "            \n",
    "        #Decay epsilon if total steps is less than decay length\n",
    "        if total_steps > 50000:\n",
    "            if epsilon_decay_length1 + 50000 > total_steps:\n",
    "                eps -= (epsilon_start-epsilon_mid)/epsilon_decay_length1\n",
    "            else:\n",
    "                eps -= (epsilon_mid-epsilon_final)/epsilon_decay_length2\n",
    "            \n",
    "        #Periodically save the model incase crash, model stored in checkpoint.pth\n",
    "        if total_steps % save_freq == 0:\n",
    "            torch.save({\n",
    "            'epoch': total_steps,\n",
    "            'model_state_dict': agent.qnet.state_dict(),\n",
    "            'optimizer_state_dict': agent.qnet_optim.state_dict()\n",
    "            }, 'checkpoint.pth')\n",
    "        \n",
    "        if terminal:\n",
    "            #clear_output(wait=True)\n",
    "            #print('Current total steps:', total_steps, 'Rewards for episode:', reward_sum)\n",
    "            break\n",
    "            \n",
    "    if reward_sum > best_reward:\n",
    "        best_reward = reward_sum\n",
    "    \n",
    "    reward_sums.append(reward_sum)\n",
    "    \n",
    "    if total_steps > learning_starts: \n",
    "        avg_episode_losses.append(sum(losses)/len(losses))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save model\n",
    "torch.save(agent.qnet.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "agent = DQNAgent(state_dim, action_dim, gamma=0.99, buffer_size=100000, tau=0.001, learning_rate=0.00025, minibatch_size=32)\n",
    "agent.qnet.load_state_dict(torch.load('model.pth'))\n",
    "agent.qnet.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Episode')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Reward per episode\n",
    "plt.plot(reward_sums)\n",
    "plt.ylabel('Reward')\n",
    "plt.xlabel('Episode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epoch (10 Episodes)')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot average reward\n",
    "reward_sums_av = []\n",
    "for i in range(0,len(reward_sums)-100,10):\n",
    "    reward_sums_av.append(sum(reward_sums[i:i+100])/100)\n",
    "    \n",
    "plt.plot(reward_sums_av)\n",
    "plt.ylabel('Average Reward per 100 Episodes')\n",
    "plt.xlabel('Epoch (10 Episodes)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play game using learnt agent\n",
    "terminal =  False\n",
    "state = env_wrap.reset()\n",
    "total_reward = 0.0\n",
    "num_actions = 0\n",
    "\n",
    "while not terminal:\n",
    "    \n",
    "    action = agent.epsilon_greedy_action( torch.from_numpy(state).float().view(-1,4,80,80).cuda() , 0.01)\n",
    "    next_state, reward, terminal, _ = env_wrap.step(action)\n",
    "    num_actions += 1\n",
    "    total_reward += reward\n",
    "    state = next_state\n",
    "    #time.sleep(0.05)\n",
    "    env_wrap.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(num_actions, total_reward)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
